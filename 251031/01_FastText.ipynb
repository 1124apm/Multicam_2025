{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f11a0a",
   "metadata": {},
   "source": [
    "## FastText\n",
    "- Word2Vec에서 OOV(사전에 없는 용어) 문제를 해결하기 위한 모델\n",
    "    - '강아지'와 '강아지들'을 다른 단어로 구분.\n",
    "- FastText는 단어를 한 글자씩 쪼개 단어의 유사도를 생성\n",
    "    - (n-gram 방식) '강아지' $\\rightarrow$ '강', '아', '지', '강아', '아지', '강아지\n",
    "    - Word2Vec와 학습 방식이 비슷하고 기본적인 매개변수도 같지만, min_n, max_n 매개변수가 존재\n",
    "        - min_n, max_n 매개변수: subword의 최소 길이와 최대 길이를 설정\n",
    "            </br>```min_n = 1, max_n = 1``` $\\rightarrow$ subword를 사용하지 않음 (Word2Vec과 같은 형태로 학습)\n",
    "\n",
    "학습 데이터가 명확한 경우(고정된 데이터) - Word2Vec이 더 효율적일 수 있음\n",
    "유저가 값을 입력하는 경우(검색 등) - FastText가 더 효율적(유사성 찾을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a0d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ac192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 문장 생성\n",
    "# 토큰화 되었다고 가정\n",
    "sentences = [\n",
    "    ['이커머스', '데이터', '분석', '진행'],\n",
    "    ['상품', '리뷰', '기반', '감성', '분석', '합니다'],\n",
    "    ['형태소', '단위', '임베딩', '가능']\n",
    "]\n",
    "\n",
    "# Fast Text 모델에 학습\n",
    "model = FastText(\n",
    "    sentences= sentences,\n",
    "    vector_size= 50,       # 단위벡터의 차원 수\n",
    "    window= 3,             # 중심단어 주변의 확인할 단어 개수\n",
    "    min_count= 1,          # 최소 출현 횟수\n",
    "    sg= 1,                 # Skip-gram 방식으로 확률 계산\n",
    "    epochs= 10,            # 학습 반복 횟수\n",
    "    min_n= 2,              # 기본값 3\n",
    "    max_n= 6               # 기본값 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c953ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.6111047e-03,  5.3626148e-04,  1.4960865e-03, -9.6691423e-04,\n",
       "        1.3344721e-03, -3.9466089e-03, -2.9213836e-03,  2.0751881e-03,\n",
       "        3.8366416e-05, -2.1776820e-03, -3.8702481e-03, -2.2806628e-03,\n",
       "       -2.0664781e-03, -7.3369575e-04, -2.6561588e-03, -1.1106797e-03,\n",
       "       -2.8349187e-03,  5.9706885e-03, -1.5937304e-03, -1.0128829e-03,\n",
       "       -1.7639366e-03,  1.1789303e-03, -1.7173518e-03,  3.7625290e-03,\n",
       "       -4.3625790e-03,  2.0642835e-03,  3.0573069e-03, -5.9944363e-03,\n",
       "       -8.2338316e-04, -1.4119033e-03,  6.8373408e-04, -2.6191517e-03,\n",
       "       -7.8321050e-04, -1.0133090e-03, -1.9886156e-03, -4.0722662e-03,\n",
       "       -3.4458062e-04,  4.2740661e-03,  1.5003346e-03,  1.2319845e-03,\n",
       "        4.7013951e-03, -3.6674424e-03,  2.4466028e-03, -2.3689321e-03,\n",
       "        1.7491765e-03, -6.5453607e-04, -2.8902704e-03, -2.6802132e-03,\n",
       "       -1.7741284e-03,  4.1342787e-03], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특정 단어의 벡터 확인\n",
    "model.wv['이커머스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c9ae40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이커머스', 0.17707844078540802),\n",
       " ('합니다', 0.17073467373847961),\n",
       " ('가능', 0.16921374201774597)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사 단어 확인\n",
    "model.wv.most_similar('데이터', topn= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285c75b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.5015250e-03, -2.2979644e-03, -2.5747030e-03,  4.0551424e-03,\n",
       "        5.9942775e-03,  7.7991433e-05, -3.3548754e-04,  1.2389648e-03,\n",
       "       -5.6767054e-03, -1.9014416e-03,  5.5394048e-04, -4.3599959e-03,\n",
       "        1.8585186e-03, -1.6516327e-03,  1.2153982e-03,  4.9254834e-03,\n",
       "       -1.0719089e-03,  1.6734168e-03, -7.5532752e-03,  9.4391109e-04,\n",
       "       -3.0809967e-03, -4.9540359e-03,  6.7945785e-04,  2.4490163e-03,\n",
       "        1.9782230e-03, -2.2293099e-03, -3.4784587e-04,  4.1471361e-04,\n",
       "        7.0494465e-03,  1.9072286e-03, -4.7399704e-03,  1.0020984e-02,\n",
       "        5.4200743e-03,  6.6835335e-03, -7.0033013e-03,  3.0829094e-03,\n",
       "        4.4810078e-03,  1.0817904e-02,  4.6293368e-03,  2.7071305e-03,\n",
       "       -4.2116926e-03, -4.7756401e-03,  2.4744410e-03, -2.6542998e-03,\n",
       "        9.1218622e-03, -2.9168790e-04,  4.3195268e-04, -6.9793002e-03,\n",
       "        4.6271365e-03,  2.2756024e-03], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 내용에 없는 단어를 확인\n",
    "model.wv['감정']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd035e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec을 이용해서 sentences를 학습하고, 없는 단어 확인\n",
    "model2 = Word2Vec(\n",
    "    sentences= sentences,\n",
    "    vector_size= 50,       # 단위벡터의 차원 수\n",
    "    window= 3,             # 중심단어 주변의 확인할 단어 개수\n",
    "    min_count= 1,          # 최소 출현 횟수\n",
    "    sg= 1,                 # Skip-gram 방식으로 확률 계산\n",
    "    epochs= 10,            # 학습 반복 횟수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0f6ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 내용에 없는 단어를 출력\n",
    "# model2.wv['감정']     # Error 발생\n",
    "\n",
    "# Word2Vec은 사전에 없는 단어를 단위벡터로 확인하면 Error 발생\n",
    "# FastText는 오탈자까지 고려\n",
    "    # 예: 검색 시 오타나도 올바른 결과가 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4160e96",
   "metadata": {},
   "source": [
    "#### Word2Vec와 FastText의 단어 간 유사도 차이\n",
    "- '강아지', '강아지들' $\\Rightarrow$ 유사한 단어\n",
    "    - Word2Vec은 다른 단어로 인식 (유사도 낮게)\n",
    "    - FastText는 비슷한 단어로 인식 (유사도 높게)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac380c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = [\n",
    "    ['고양이', '고양이들', '귀엽다', '동물', '반려동물'],\n",
    "    ['강아지', '강아지들', '귀엽다', '동물', '반려동물'],\n",
    "    ['달리다', '달리는', '달림', '걷다', '걷는'],\n",
    "    ['빠르다', '빠른', '느리다', '느림'],\n",
    "    ['예쁘다', '예쁨', '예쁜', '매력적이다'],\n",
    "    ['컴퓨팅', '컴퓨터', '컴퓨터들', '기계']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b85eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "# Word2Vec\n",
    "w2v = Word2Vec(\n",
    "    sentences= sentences2,\n",
    "    vector_size= 100,\n",
    "    window= 3,\n",
    "    min_count= 1,\n",
    "    sg= 1,\n",
    "    epochs= 50,\n",
    "    seed= 42\n",
    ")\n",
    "\n",
    "# FastText\n",
    "ft = FastText(\n",
    "    sentences= sentences2,\n",
    "    vector_size= 100,\n",
    "    window= 3,\n",
    "    min_count= 1,\n",
    "    sg= 1,\n",
    "    epochs= 50,\n",
    "    seed= 42,\n",
    "    min_n= 2,\n",
    "    max_n= 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc99d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec 유사도:  0.20342888\n",
      "FastText 유사도:  0.38520095\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec의 유사도 확인\n",
    "print( 'Word2Vec 유사도: ', w2v.wv.similarity('강아지', '강아지들') )\n",
    "\n",
    "# FastText의 유사도 확인\n",
    "print( 'FastText 유사도: ', ft.wv.similarity('강아지', '강아지들') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58039c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '강아지', '강아지들'의 유사도 ] \n",
      " Word2Vec: 0.2034 \n",
      " FastText: 0.3852\n",
      "[ '고양이', '고양이들'의 유사도 ] \n",
      " Word2Vec: -0.1262 \n",
      " FastText: 0.3965\n",
      "[ '달리다', '달리는'의 유사도 ] \n",
      " Word2Vec: -0.0706 \n",
      " FastText: 0.2667\n",
      "[ '예쁘다', '예쁜'의 유사도 ] \n",
      " Word2Vec: 0.1392 \n",
      " FastText: 0.0695\n",
      "[ '컴퓨터', '컴퓨팅'의 유사도 ] \n",
      " Word2Vec: -0.0516 \n",
      " FastText: 0.3857\n",
      "[ '빠르다', '느림'의 유사도 ] \n",
      " Word2Vec: 0.0108 \n",
      " FastText: -0.0127\n"
     ]
    }
   ],
   "source": [
    "# 비교 대상 단어들\n",
    "test_text = [\n",
    "    ['강아지', '강아지들'],\n",
    "    ['고양이', '고양이들'],\n",
    "    ['달리다', '달리는'],\n",
    "    ['예쁘다', '예쁜'],\n",
    "    ['컴퓨터', '컴퓨팅'],\n",
    "    ['빠르다', '느림']\n",
    "]\n",
    "\n",
    "for a, b in test_text:\n",
    "    w2v_sim = float(w2v.wv.similarity(a, b))    # 유사도 데이터를 실수형으로 변경\n",
    "    ft_sim = float(ft.wv.similarity(a, b))      # 유사도 데이터를 실수형으로 변경\n",
    "    print(f\"[ '{a}', '{b}'의 유사도 ] \\n Word2Vec: {w2v_sim :.4f} \\n FastText: {ft_sim :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5adccb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['무선', '이어폰', '블루투스', '노이즈캔슬링', '충전케이스'],\n",
       " ['유선', '이어폰', '하이파이', '금도금', '플러그'],\n",
       " ['게이밍', '마우스', 'RGB', '경량', '디자인'],\n",
       " ['무선', '마우스', '초경량', '블루투스', '듀얼모드'],\n",
       " ['헤드폰', '노이즈캔슬링', '유선']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상품명을 기준으로 특정 상품 검색 시, 연관된 상품의 목록을 확인\n",
    "products = {\n",
    "    'P001': '무선 이어폰 블루투스 노이즈캔슬링 충전케이스',\n",
    "    'P002': '유선 이어폰 하이파이 금도금 플러그',\n",
    "    'P003': '게이밍 마우스 RGB 경량 디자인',\n",
    "    'P004': '무선 마우스 초경량 블루투스 듀얼모드',\n",
    "    'P005': '헤드폰 노이즈캔슬링 유선'\n",
    "}\n",
    "\n",
    "# FastText 통해 학습하기 위해 products에서 데이터를 추출\n",
    "# 필요한 데이터는 dict형 데이터의 values\n",
    "datas = products.values()\n",
    "\n",
    "# 공백을 기준으로 슬라이싱\n",
    "tokens = []\n",
    "for data in datas:\n",
    "    tokens.append( data.split() )\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf1f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 데이터를 이용하여 FastText에 학습\n",
    "ft2 = FastText(\n",
    "    sentences= tokens,\n",
    "    vector_size= 100,\n",
    "    window= 3,\n",
    "    min_count= 1,\n",
    "    sg= 1,\n",
    "    epochs= 10,\n",
    "    min_n= 3,   # min_n, max_n 둘 다 1로 두면 'subword'를 사용하지 않는다는 의미 = 'Word2Vec'을 사용한다는 의미\n",
    "    max_n= 6,   # 여기선 subword를 사용하는 FastText 모델에 학습\n",
    "    seed= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40d7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0608668e-03, -5.0734571e-04,  6.8453950e-04,  1.6416922e-03,\n",
       "        1.0831023e-03, -6.5104905e-05, -4.1719939e-04, -7.2870782e-04,\n",
       "       -4.8853789e-04, -4.6182857e-03,  2.4489574e-03,  6.1499518e-03,\n",
       "       -1.5955068e-03,  1.5212459e-03,  2.9862362e-03,  4.7445744e-03,\n",
       "        1.7521627e-03, -3.0767897e-03,  2.4293065e-03, -3.7023224e-04,\n",
       "       -3.0174854e-03, -4.6088859e-05, -2.1022612e-03,  4.2979121e-03,\n",
       "        8.0651295e-04,  5.2311446e-04, -1.1054744e-03,  2.4524573e-03,\n",
       "       -1.4782109e-03,  9.9279720e-04,  8.7367334e-05, -5.9449538e-03,\n",
       "       -3.3011988e-03, -1.3528297e-04, -4.6411299e-04,  3.0999838e-03,\n",
       "        2.0988486e-03,  5.7990261e-04, -2.6780847e-06,  1.6811772e-03,\n",
       "       -2.5592633e-03,  2.4090365e-03,  1.9723834e-03, -5.7378702e-04,\n",
       "       -3.7561278e-03,  3.8244107e-03, -1.1656301e-03,  1.8521851e-03,\n",
       "        2.3929658e-03, -1.6058824e-03, -6.8952364e-04,  2.5542639e-04,\n",
       "       -2.5633242e-04,  1.6509496e-03, -1.7838118e-03, -9.2189008e-04,\n",
       "        8.6162920e-04, -6.4000465e-05, -7.1046752e-04,  9.3032449e-04,\n",
       "        3.8722623e-03,  1.3343798e-03, -2.5869855e-03,  4.5031090e-03,\n",
       "        3.9240411e-05, -2.0922620e-03,  2.9661553e-04, -1.1472647e-03,\n",
       "       -4.0264218e-03, -1.5765575e-03, -1.0855849e-03,  9.1560703e-04,\n",
       "       -1.3233506e-03, -1.1053964e-03,  1.9911784e-03, -8.4884866e-04,\n",
       "       -5.8481423e-04,  1.8181965e-03,  1.4427151e-04, -1.8085071e-03,\n",
       "       -1.6281120e-03, -9.5857838e-05, -2.2511759e-03,  3.0856545e-03,\n",
       "        5.8991701e-04,  2.7316276e-03,  7.2527130e-04, -5.8481080e-04,\n",
       "        6.6993851e-04, -1.7833678e-03,  2.3278259e-03,  2.3277227e-03,\n",
       "       -1.2308987e-03, -2.7100000e-04,  9.6427137e-04, -1.4270113e-03,\n",
       "       -5.7787541e-04,  1.4606221e-03, -1.2615648e-03, -5.9212651e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단위 벡터 확인 -> vector_size 차원의 좌표를 의미하는 값\n",
    "ft2.wv['마우스']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916ae937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d8891ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 평균 벡터를 구하는 함수 정의\n",
    "def sent_vec(token):\n",
    "    vecs = []\n",
    "    for w in token:\n",
    "        vecs.append(ft.wv[w])\n",
    "    # 해당 vecs가 존재하지 않는다면 희소행렬을 반환\n",
    "    if not vecs:\n",
    "        return np.zeros(ft.vector_size)\n",
    "    print(np.array(vecs).shape)\n",
    "    v = np.mean(vecs, axis=0)\n",
    "    # 일반적인 문장의 평균 벡터를 구하는 식\n",
    "    # 성능을 올리기 위해서는 L2 정규화 -> 벡터의 거리롤 나눠준다.\n",
    "    if type == 'l2':\n",
    "        v = v / (np.linalg.norm(v) + 1e-12)   \n",
    "    # 1e-12를 더해 0으로 나눠지는 것을 방지\n",
    "    print(v.shape)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7fac177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 100)\n",
      "(100,)\n",
      "(5, 100)\n",
      "(100,)\n",
      "(5, 100)\n",
      "(100,)\n",
      "(5, 100)\n",
      "(100,)\n",
      "(3, 100)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# 토큰화된 데이터들을 평균 벡터로 변환\n",
    "item_vecs = []\n",
    "for t in tokens:\n",
    "    # print(sent_vec(t))\n",
    "    # break\n",
    "    item_vecs.append(sent_vec(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e57b8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 벡터를 이용해 코사인 유사도 확인\n",
    "# 코사인 유사도 함수 로드\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5872330e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08545259, 0.09662661, 1.0000001 , 0.21450484, 0.09070536]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = list(products.keys()).index('P003')\n",
    "cosine_similarity(item_vecs[idx:idx+1], item_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46afaebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도를 이용해 가장 근접한 상품의 이름을 출력\n",
    "# 추천하는 함수를 생성\n",
    "def recommand_by_text(product_id):\n",
    "    # 해당 상품명의 위치값 (item_vecs 위치를 이용해 코사인 유사도 생성)\n",
    "    # 상품의 id값들은 products라는 dict에서 해당 id의 위치를 저장\n",
    "    idx = list(products.keys()).index(product_id)\n",
    "\n",
    "    # item_vecs에서 해당 인덱스의 값과 전체 vectors의 값을 비교\n",
    "    # 한 문장의 코사인 유사도를 확인하기 때문에, 2차원이 아닌 1차원 데이터를 생성\n",
    "    # ravel()을 이용해 1차원으로 변환\n",
    "    # id를 여러 개 넣어 확인한다면 반복문을 만들면 된다.\n",
    "    sims = cosine_similarity(item_vecs[idx:idx+1], item_vecs).ravel()\n",
    "    \n",
    "    # 내림차순 정렬\n",
    "    order = sims.argsort()[::-1]\n",
    "    # 추천 단어들을 출력\n",
    "    rec = []\n",
    "    for i in order:\n",
    "        # 코사인 유사도에서 같은 id라면 추천하지 않는다.\n",
    "        if list(products.keys())[i] != product_id:\n",
    "            # 상품의 id와 유사도 값들을 rec에 추가\n",
    "            rec.append( [list(products.keys())[i], sims[i]] )\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "089afe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['P004', np.float32(0.5282915)],\n",
       " ['P002', np.float32(0.3743211)],\n",
       " ['P005', np.float32(0.36722618)],\n",
       " ['P003', np.float32(0.085452594)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_list = recommand_by_text('P001')\n",
    "rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc9e6c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무선 마우스 초경량 블루투스 듀얼모드\n",
      "유선 이어폰 하이파이 금도금 플러그\n"
     ]
    }
   ],
   "source": [
    "# 유사도가 높은 상위 2개 상품의 이름을 확인\n",
    "# 방법 1\n",
    "for pid, _ in rec_list[:2]:\n",
    "    print(products[pid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed94eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 방법 2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pid, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rec_list):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mproducts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m idx == \u001b[32m1\u001b[39m:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "# 방법 2\n",
    "for pid, _ in enumerate(rec_list):\n",
    "    print(products[pid])\n",
    "    if idx == 1:\n",
    "        break\n",
    "# Error 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96c0407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무선 마우스 초경량 블루투스 듀얼모드\n",
      "유선 이어폰 하이파이 금도금 플러그\n"
     ]
    }
   ],
   "source": [
    "# 방법 2\n",
    "for idx, (pid, _) in enumerate(rec_list):\n",
    "    print(products[pid])\n",
    "    if idx == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211a0b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션에 따른 물품 추천\n",
    "sessions = [\n",
    "    ['P001', 'P004'],           # 무선 이어폰 - 무선 마우스\n",
    "    ['P001', 'P002'],           # 무선 이어폰 - 유선 이어폰\n",
    "    ['P003', 'P004'],           # 게이밍 마우스 - 무선 마우스\n",
    "    ['P005', 'P001'],           # 헤드폰 - 무선 이어폰\n",
    "    ['P002', 'P005'],           # 유선 이어폰 - 헤드폰\n",
    "    ['P003', 'P004', 'P001']    # 게이밍마우스 - 무선 마우스 - 이어폰\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 식별자인 id를 기준으로 임베딩을 하는 경우에는 subword 불필요\n",
    "# FastText에서 매개변수 min_n, max_n을 1로 입력\n",
    "ft_item = FastText(\n",
    "    sentences= sessions,\n",
    "    vector_size= 50,\n",
    "    window= 3,\n",
    "    sg= 1,\n",
    "    epochs= 50,\n",
    "    min_count= 1,   # 기본값이 5 - min_count를 잡아두지 않으면 학습 데이터가 아무것도 없어져서 Error\n",
    "    min_n= 1,\n",
    "    max_n= 1,\n",
    "    seed= 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ff6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w2v_item = Word2Vec(\n",
    "    sentences= sessions,\n",
    "    vector_size= 100,\n",
    "    window= 3,\n",
    "    sg= 1,\n",
    "    min_count= 1,\n",
    "    epochs= 50,\n",
    "    seed= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa942a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션을 통한 물건을 추천하는 함수를 정의\n",
    "def recommand_by_session(product_id, text_model, n = 3):\n",
    "    # product_id: 상품의 id (첫 번째 검색하는 아이템의 id)\n",
    "    # text_model: 학습된 모델\n",
    "    # n: 유사도 높은 상위 n개 출력\n",
    "    # 유사한 단어를 출력해주는 함수(most_similar)\n",
    "    recs = text_model.wv.most_similar( product_id, topn = n )\n",
    "    # most_similar()의 결과값은 [ (item_id, 유사도), ...]\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af426ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P002', 0.6542717218399048),\n",
       " ('P005', 0.6441062688827515),\n",
       " ('P004', 0.6383542418479919)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommand_by_session('P001', ft_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
