{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b53900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6641e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치 \n",
    "# !pip install torch torchvision torchaudio\n",
    "# 라이브러리 로드 \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfecd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 생성 \n",
    "# 독립, 종속 -> 파이토치에서는 독립, 종속 변수의 데이터의 타입은 Tensor 로 구성\n",
    "# 독립 변수 -> 2차원 데이터\n",
    "# 종속 변수 -> 2차원 데이터 (sklearn에서는 1차원)\n",
    "X = torch.tensor( [ [1.0], [2.0], [3.0], [4.0] ] )  # 4행 1열\n",
    "# 종속 변수는 독립 변수 데이터에서 2를 곱하고 1을 더해준 값으로 생성\n",
    "Y = torch.tensor( [ [3.0], [5.0], [7.0], [9.0] ] )  # 4행 1열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd03b9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac500ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀 \n",
    "class LinearReg(nn.Module):\n",
    "    # 생성자 함수 \n",
    "    def __init__(self):\n",
    "        # self: 클래스가 생성된 메모리의 주소\n",
    "        # super(): 부모 클래스(nn.Module) <-- 상속\n",
    "        super( LinearReg, self ).__init__()   # 부모 클래스의 생성자 함수를 실행\n",
    "        # Linear()의 첫 번째 인자 - 입력 데이터(독립의 피쳐)의 크기\n",
    "            # 두 번째 인자 - 출력 데이터(종석의 피쳐)의 크기\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e871ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성 (회귀 모델)\n",
    "# LinearReg 클래스에서, 생성자 함수 중 self를 제외하고 매개변수가 존재하지 않으므로\n",
    "# 클래스 생성 시 넣어야 할 인자값 없음\n",
    "model = LinearReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783d678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "criterion = nn.MSELoss()\n",
    "# 가중치 갱신 (경사 하강법)\n",
    "# lr은 가중치를 변환할 때의 변환 비율\n",
    "# 경사 하강법의 목적은 가중치를 천천히 내리며 최적의 조건을 찾는 것인데, 너무 크게 잡으면 그 구간을 지나갈 수도 있음.\n",
    "# 너무 세세하게 잡으면 학습 시간이 너무 오래 걸림.\n",
    "optimizer = optim.SGD(model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdbf7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50, 500], Loss: 0.0\n",
      "Epoch: [100, 500], Loss: 0.0\n",
      "Epoch: [150, 500], Loss: 0.0\n",
      "Epoch: [200, 500], Loss: 0.0\n",
      "Epoch: [250, 500], Loss: 0.0\n",
      "Epoch: [300, 500], Loss: 0.0\n",
      "Epoch: [350, 500], Loss: 0.0\n",
      "Epoch: [400, 500], Loss: 0.0\n",
      "Epoch: [450, 500], Loss: 0.0\n",
      "Epoch: [500, 500], Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 500번 반복 실행하면서 Loss를 확인\n",
    "for epoch in range(500):\n",
    "    # 순전파\n",
    "    Y_pred = model(X)\n",
    "    # 손실 함수\n",
    "    loss = criterion(Y_pred, Y)\n",
    "    # 역전파\n",
    "    optimizer.zero_grad()       # 기울기 초기화\n",
    "    loss.backward()             # 기울기 계산\n",
    "    optimizer.step()            # 파라미터를 업데이트\n",
    "\n",
    "    # 50회마다 loss의 값을 출력\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f'Epoch: [{epoch+1}, 500], Loss: {round(loss.item(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841b6364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독립: 1.0, 종속: 3.0, 예측: 2.9989938735961914\n",
      "독립: 2.0, 종속: 5.0, 예측: 4.999512195587158\n",
      "독립: 3.0, 종속: 7.0, 예측: 7.000030517578125\n",
      "독립: 4.0, 종속: 9.0, 예측: 9.00054931640625\n"
     ]
    }
   ],
   "source": [
    "# 예측값 확인\n",
    "pred = model(X).detach()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(f\"독립: {X[i].item()}, 종속: {Y[i].item()}, 예측: {pred[i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1847d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn에서 제공하는 캘리포니아 집값 데이터를 이용하여 회귀 분석\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f98e68e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "독립 변수 데이터의 크기:  (20640, 8)\n",
      "종속 변수 데이터의 크기:  (20640,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드해 독립 종속 변수 데이터 생성\n",
    "data = fetch_california_housing()\n",
    "\n",
    "X = data['data']\n",
    "Y = data['target']\n",
    "\n",
    "print('독립 변수 데이터의 크기: ', X.shape)\n",
    "print('종속 변수 데이터의 크기: ', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec158269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 학습, 평가 데이터로 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c21793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler를 이용하여 스케일링\n",
    "# train 데이터를 기준으로 fitting (= train 데이터를 기준으로 범위를 지정)\n",
    "    # 일반적으로 train, test 모두 같은 fit model에서 변환 작업해야 함\n",
    "scaler= StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f842eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 4개의 데이터의 타입은 현재 array 형태 -> Tensor 형태로 변환\n",
    "X_train_sc_tensor = torch.tensor( X_train_sc, dtype= torch.float32 )\n",
    "X_test_sc_tensor = torch.tensor( X_test_sc, dtype= torch.float32 )\n",
    "# 스케일링한 데이터와 하지 않은 데이터 비교\n",
    "X_train_tensor = torch.tensor( X_train, dtype= torch.float32 )\n",
    "X_test_tensor = torch.tensor( X_test, dtype= torch.float32 )\n",
    "\n",
    "# 종속 변수 Y의 데이터는 현재 1차원 데이터 -> 2차원 데이터로 변환 -> Tensor 형태로 변환\n",
    "Y_train_tensor = torch.tensor( Y_train.reshape(-1, 1), dtype= torch.float32 )\n",
    "Y_test_tensor = torch.tensor( Y_test.reshape(-1, 1), dtype= torch.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1e37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 생성\n",
    "class Reg(nn.Module):\n",
    "    # 생성자 함수에서 self를 제외한 매개변수로 _dim을 지정\n",
    "    # nn.linear()의 첫 번째 인자 - 입력값의 열의 크기\n",
    "    def __init__(self, _dim):\n",
    "        super(Reg, self).__init__()\n",
    "        self.linear = nn.Linear(_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4316c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성\n",
    "# 학습 데이터의 피쳐의 개수\n",
    "reg_model = Reg( X_train_sc.shape[1] )  # 8이 아닌 1인 이유: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b52a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "criterion = nn.MSELoss()\n",
    "# 가중치 변환\n",
    "optimizer = optim.SGD( reg_model.parameters(), lr= 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142a5fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30, 1000], Loss: 1.9089\n",
      "Epoch: [60, 1000], Loss: 1.0292\n",
      "Epoch: [90, 1000], Loss: 0.7581\n",
      "Epoch: [120, 1000], Loss: 0.6682\n",
      "Epoch: [150, 1000], Loss: 0.6337\n",
      "Epoch: [180, 1000], Loss: 0.6168\n",
      "Epoch: [210, 1000], Loss: 0.6059\n",
      "Epoch: [240, 1000], Loss: 0.5975\n",
      "Epoch: [270, 1000], Loss: 0.5902\n",
      "Epoch: [300, 1000], Loss: 0.5838\n"
     ]
    }
   ],
   "source": [
    "# 학습 반복 실행\n",
    "# 아까는 행 4개, 열 1개라 금방 끝났지만, 지금은 행 16512개, 열 8개라 시간이 더 걸리므로 300번만 실행\n",
    "for epoch in range(300):\n",
    "    # 순전파\n",
    "    Y_pred = reg_model( X_train_sc_tensor )\n",
    "    # 손실 함수\n",
    "    loss = criterion( Y_pred, Y_train_tensor )\n",
    "    # 기울기 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 역전파\n",
    "    loss.backward()\n",
    "    # 가중치 업데이트\n",
    "    optimizer.step()\n",
    "    # 30회마다 loss의 값을 출력해 변환 확인\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        print(f'Epoch: [{epoch+1}, 1000], Loss: {round(loss.item(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d43d909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reg(\n",
       "  (linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 모델의 학습 모드 -> 평가 모드로 변경 (학습 중지 X, 모드 변경 O)\n",
    "# eval() 메서드: 평가 모드로 변경 (드롭아웃, 배치 정규화 등 학습 시에만 적용되는 기능들을 평가 시에 적용되지 않도록 변경)\n",
    "# train() 메서드: 다시 학습 모드로 변경\n",
    "reg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aff8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측과 평가\n",
    "# torch.no_grad(): 평가 시에 기울기(gradient) 계산을 하지 않도록 설정 -> 속도 증가해 메모리 절약\n",
    "with torch.no_grad():\n",
    "    Y_pred = reg_model( X_test_sc_tensor )  # test 데이터로 예측,\n",
    "    test_loss = criterion( Y_pred, Y_test_tensor )  #  \"   손실 함수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d843aec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 MSE:  0.5983\n",
      "테스트 데이터의 RMSE:  0.7735\n"
     ]
    }
   ],
   "source": [
    "# 성능 평가 지표\n",
    "# MSE, RMSE 확인\n",
    "rmse = np.sqrt(test_loss.item())\n",
    "print('테스트 데이터의 MSE: ', round(test_loss.item(), 4))\n",
    "print('테스트 데이터의 RMSE: ', round(rmse, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e35f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 값: 0.477, 예측 값: 0.963\n",
      "실제 값: 0.458, 예측 값: 1.593\n",
      "실제 값: 5.00001, 예측 값: 2.401\n",
      "실제 값: 2.186, 예측 값: 2.723\n",
      "실제 값: 2.78, 예측 값: 2.215\n",
      "실제 값: 1.587, 예측 값: 2.135\n",
      "실제 값: 1.982, 예측 값: 2.706\n",
      "실제 값: 1.575, 예측 값: 2.177\n",
      "실제 값: 3.4, 예측 값: 2.184\n",
      "실제 값: 4.466, 예측 값: 4.116\n"
     ]
    }
   ],
   "source": [
    "# 실제 값과 예측 값 비교\n",
    "# 상위 10개만 출력해 확인\n",
    "for i in range(10):\n",
    "    print(f'실제 값: {Y_test[i].item()}, 예측 값: {round(Y_pred[i].item(), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9edf127",
   "metadata": {},
   "source": [
    "---\n",
    "연습\n",
    "- 스탠다드 스케일링을 하지 않은 데이터로 학습하고 예측을 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "272aba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg(\n",
      "  (linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "reg_model2 = Reg( X_train.shape[1] )\n",
    "print(reg_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aecbf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수\n",
    "criterion2 = nn.MSELoss()\n",
    "# 가중치 변환\n",
    "# Adam 옵티마이저: 적응적 학습률 기반 경사하강법\n",
    "# 위처럼 SGD로 하면 NaN이 발생하는 경우가 있는데, Adam은 그런 경우가 거의 없음\n",
    "optimizer2 = optim.Adam( reg_model2.parameters(), lr= 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6a0e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 423.9258\n",
      "Epoch: 60, Loss: 248.1688\n",
      "Epoch: 90, Loss: 155.2445\n",
      "Epoch: 120, Loss: 101.3368\n",
      "Epoch: 150, Loss: 65.0121\n",
      "Epoch: 180, Loss: 42.7024\n",
      "Epoch: 210, Loss: 30.033\n",
      "Epoch: 240, Loss: 23.2073\n",
      "Epoch: 270, Loss: 19.5866\n",
      "Epoch: 300, Loss: 17.5729\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300):\n",
    "    # 순전파\n",
    "    Y_pred2 = reg_model2( X_train_tensor )\n",
    "    # 손실 함수\n",
    "    loss2 = criterion2( Y_pred2, Y_train_tensor )\n",
    "    # 기울기 초기화\n",
    "    optimizer2.zero_grad()\n",
    "    # 역전파\n",
    "    loss2.backward()\n",
    "    # 가중치 업데이트\n",
    "    optimizer2.step()\n",
    "    # 30회마다 loss2의 값을 출력해 변환 확인\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        print(f'Epoch: {epoch+1}, Loss: {round(loss2.item(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93913b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model2.eval()\n",
    "with torch.no_grad():\n",
    "    Y_pred2 = reg_model2(X_test_tensor)\n",
    "    test_loss2 = criterion2(Y_pred2, Y_test_tensor).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e81a559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 값: 0.477, 예측 값: 0.7937\n",
      "실제 값: 0.458, 예측 값: 2.5152\n",
      "실제 값: 5.00001, 예측 값: 9.9949\n"
     ]
    }
   ],
   "source": [
    "# 실제 값과 예측 값 비교\n",
    "for i in range(3):\n",
    "    print(f'실제 값: {Y_test[i].item()}, 예측 값: {round(Y_pred2[i].item(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81d55643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 MSE (스케일링 X):  17.1117\n",
      "테스트 데이터의 RMSE (스케일링 X):  4.1366\n"
     ]
    }
   ],
   "source": [
    "# mse 보는 게 나을 것 같음\n",
    "rmse2 = np.sqrt(test_loss2)\n",
    "print('테스트 데이터의 MSE (스케일링 X): ', round(test_loss2, 4))\n",
    "print('테스트 데이터의 RMSE (스케일링 X): ', round(rmse2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9958bb",
   "metadata": {},
   "source": [
    "---\n",
    "### 파이토치를 이용한 분류 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bccf6f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 로드\n",
    "# iris 데이터를 이용\n",
    "from sklearn.datasets import load_iris\n",
    "# 분류 검증 정확도\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc83aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "Y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "109e4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 분할\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state= 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ca71722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스탠다드 스케일러를 이용한 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)   # 위의 연습처럼 스케일링하지 않은 데이터를 쓰지 않음\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ff4a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 모델에서 Tensor 데이터로 변환\n",
    "# 독립 변수 -> float32 타입으로 변경\n",
    "X_train_tensor = torch.tensor(X_train, dtype= torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype= torch.float32)\n",
    "# 종속 변수 -> long 타입으로 변경 (분류 모델에서는 정수 형태여야 하므로)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype= torch.long)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype= torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7aefa1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 0,\n",
       "        2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1,\n",
       "        0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0,\n",
       "        0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_tensor\n",
    "# 0, 1, 2로 구성된 정수 형태임 -> 세 가지 품종을 분류하는 문제임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7d834a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# (150, 4) -> 피쳐가 4개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94985caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class IrisClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모 클래스의 생성자 함수 실행\n",
    "        super(IrisClass, self).__init__()\n",
    "        # 분류 모델 선택\n",
    "        self.model = nn.Sequential(\n",
    "            # Linear(열의 개수, 분류 클래스의 개수(이 경우 0,1,2 세 가지))\n",
    "            nn.Linear(4, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a81dfc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "cls_model = IrisClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c30d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 / 옵티마이저 생성\n",
    "# 분류 모델에서의 손실 함수\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 옵티마이저\n",
    "optimizer = optim.SGD(cls_model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd235a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.9652\n",
      "Epoch: 60, Loss: 0.7877\n",
      "Epoch: 90, Loss: 0.6768\n",
      "Epoch: 120, Loss: 0.6056\n",
      "Epoch: 150, Loss: 0.5573\n",
      "Epoch: 180, Loss: 0.5229\n",
      "Epoch: 210, Loss: 0.497\n",
      "Epoch: 240, Loss: 0.4767\n",
      "Epoch: 270, Loss: 0.4604\n",
      "Epoch: 300, Loss: 0.4468\n"
     ]
    }
   ],
   "source": [
    "# 반복 학습 시행\n",
    "for epoch in range(300):\n",
    "    # 순전파\n",
    "    Y_pred = cls_model(X_train_tensor)\n",
    "    # 손실 함수\n",
    "    loss = criterion(Y_pred, Y_train_tensor)\n",
    "    # 역전파\n",
    "    optimizer.zero_grad()       # 기울기 초기화\n",
    "    loss.backward()             # 기울기 계산\n",
    "    optimizer.step()            # 파라미터를 업데이트\n",
    "\n",
    "    # 30회마다 loss의 값을 출력\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        print(f'Epoch: {epoch+1}, Loss: {round(loss.item(), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3e3f2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류 모델의 정확도:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 평가 - 실제 값과 예측 값 비교\n",
    "# 정확도\n",
    "cls_model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = cls_model(X_test_tensor)\n",
    "    # torch.argmax(): 텐서에서 최댓값이 위치하는 인덱스만 반환\n",
    "    # torch.max(): 특정 차원에서 최댓값 자체와 그 값이 위치하는 인덱스를 함께 반환\n",
    "    pred_idx = torch.argmax(pred, axis=1)  # 예측 값에서 가장 큰 값의 인덱스를 반환\n",
    "    # 정확도를 계산\n",
    "    acc = accuracy_score(Y_test, pred_idx)\n",
    "print('분류 모델의 정확도: ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2bda61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0025,  1.0266,  0.6385],\n",
       "        [ 1.2278, -0.6373, -1.3158],\n",
       "        [-2.9213,  2.3584,  3.3738],\n",
       "        [-0.8246,  0.7221,  0.7899],\n",
       "        [-1.5411,  1.4088,  1.3517],\n",
       "        [ 0.9200, -0.4953, -1.4522],\n",
       "        [-0.3705,  0.3331,  0.0942],\n",
       "        [-1.4249,  0.9487,  2.3142],\n",
       "        [-1.8894,  1.5472,  0.9929],\n",
       "        [-0.8022,  0.7578,  0.2349],\n",
       "        [-0.9598,  0.7029,  1.7384],\n",
       "        [ 0.8784, -0.3826, -2.1532],\n",
       "        [ 1.0504, -0.5183, -1.6257],\n",
       "        [ 0.9256, -0.3993, -2.0655],\n",
       "        [ 1.6758, -1.0469, -1.7948],\n",
       "        [-0.5534,  0.5159,  1.1135],\n",
       "        [-1.3695,  1.0044,  2.1154],\n",
       "        [-0.9094,  0.8703,  0.0151],\n",
       "        [-0.7118,  0.7057,  0.3964],\n",
       "        [-1.5335,  1.0981,  2.0115],\n",
       "        [ 1.1631, -0.6294, -2.0990],\n",
       "        [-0.8788,  0.6796,  1.2325],\n",
       "        [ 1.1825, -0.7135, -1.7140],\n",
       "        [-1.5152,  1.1303,  1.9179],\n",
       "        [-1.3409,  1.2510,  3.0104],\n",
       "        [-1.4337,  0.9520,  2.2042],\n",
       "        [-2.0966,  1.7568,  1.9268],\n",
       "        [-1.3473,  0.9758,  2.4314],\n",
       "        [ 0.8418, -0.4469, -1.9660],\n",
       "        [ 0.9613, -0.4683, -2.0188]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n",
    "# 열이 3개 -> 3개의 클래스에 대한 예측 엔트로피 계수를 의미\n",
    "# 세 열 중 가장 높은 값을 예측한 클래스로 판단\n",
    "# 0번째 열: 클래스 0에 대한 예측 확률\n",
    "# 1번째 열: 클래스 1에 대한 예측 확률\n",
    "# 2번째 열: 클래스 2에 대한 예측 확률"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
