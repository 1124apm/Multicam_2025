{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcc95e7",
   "metadata": {},
   "source": [
    "#### SBERT\n",
    "- BERT 모델: 문장 이해용 Encoder\n",
    "    - 문장 쌍 비교\n",
    "- SBERT 모델: 문장 의미 임베딩\n",
    "    - 벡터의 비교용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc4d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8478c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0749539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\student\\.cache\\huggingface\\hub\\models--jhgan--ko-sroberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "No sentence-transformers model found with name BM-K/KoSimCSE-roberta-multitask. Creating a new one with mean pooling.\n",
      "c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\student\\.cache\\huggingface\\hub\\models--BM-K--KoSimCSE-roberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# 모델을 로드 -> 두 개의 문장을 비교 (코사인 유사도를 통해 두 문장이 얼마나 근접한지 확인)\n",
    "# 다목적 한국어 SBERT\n",
    "model_name = 'jhgan/ko-sroberta-multitask'\n",
    "# 또는\n",
    "# 문장 유사도 특화\n",
    "model_name2 = 'BM-K/KoSimCSE-roberta-multitask'\n",
    "\n",
    "sbert = SentenceTransformer(model_name)\n",
    "sbert2 = SentenceTransformer(model_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038dfca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 토큰의 길이를 설정\n",
    "sbert.max_seq_length = 256\n",
    "sbert2.max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d36c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 문장을 비교\n",
    "doc1 = \"이 카메라는 색감이 자연스럽고 배터리도 오래간다\"\n",
    "doc2 = \"배터리 성능이 좋고 사진 품질이 뛰어나다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca03ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도:  0.6948\n"
     ]
    }
   ],
   "source": [
    "# 두 개의 문장을 임베딩하고 코사인 유사도 계산\n",
    "# sbert인 경우\n",
    "with torch.inference_mode():\n",
    "    emb1 = sbert.encode(doc1, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb2 = sbert.encode(doc2, convert_to_tensor=True, normalize_embeddings=True)\n",
    "# 코사인 유사도 계산\n",
    "cos_sim = util.cos_sim(emb1, emb2).item()\n",
    "print('유사도: ', round(cos_sim, 4))\n",
    "# 유사도 0.6948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "309e0339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사도:  0.734\n"
     ]
    }
   ],
   "source": [
    "# 두 개의 문장을 임베딩하고 코사인 유사도 계산\n",
    "# sbert2인 경우\n",
    "with torch.inference_mode():\n",
    "    emb1 = sbert2.encode(doc1, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    emb2 = sbert2.encode(doc2, convert_to_tensor=True, normalize_embeddings=True)\n",
    "# 코사인 유사도 계산\n",
    "cos_sim = util.cos_sim(emb1, emb2).item()\n",
    "print('유사도: ', round(cos_sim, 4))\n",
    "# 유사도 0.734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31e80d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2491f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.3585, -0.0052],\n",
      "        [ 0.3585,  1.0000,  0.1199],\n",
      "        [-0.0052,  0.1199,  1.0000]])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    '삼성전자 주가가 올랐다',\n",
    "    '코스피가 상승 마감했다',\n",
    "    '비가 많이 와서 항공편이 취소됐다'\n",
    "]\n",
    "# 0, 1번째 문장과 비슷한 다른 문장을 sentences와 비교해보기\n",
    "with torch.inference_mode():\n",
    "    embs = sbert2.encode(sentences, convert_to_tensor= True, normalize_embeddings= True)\n",
    "    # 임베드 벡터 3개, 컬럼 768개\n",
    "\n",
    "# 세 문장에서의 유사도 확인\n",
    "sim_metrix = util.cos_sim(embs, embs)\n",
    "print(sim_metrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6f8c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6161, 0.6014]),\n",
       "indices=tensor([0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence = \"증시가 강세였다\"\n",
    "# 임베딩\n",
    "new_emb = sbert2.encode(new_sentence, convert_to_tensor= True, normalize_embeddings= True)\n",
    "\n",
    "# 유사도가 높은 상위 n개 확인\n",
    "top_n = 2\n",
    "hits = torch.topk(\n",
    "    util.cos_sim(new_emb, embs).squeeze(0),     # squeeze로 차원 하나 떨어뜨림\n",
    "    k= top_n\n",
    ")\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c273ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자 주가가 올랐다 | score: 0.616\n",
      "코스피가 상승 마감했다 | score: 0.601\n"
     ]
    }
   ],
   "source": [
    "for score, idx in zip( hits.values.tolist(), hits.indices.tolist() ):\n",
    "    print(f\"{sentences[idx]} | score: {score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
