{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc0db438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치\n",
    "# !pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "445236d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '학교', '에', '간다']\n"
     ]
    }
   ],
   "source": [
    "# Java 설치 확인\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "print(okt.morphs('나는 학교에 간다'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a6d66",
   "metadata": {},
   "source": [
    "# 데이터의 분할\n",
    "KFold의 분할 방식\n",
    "- KFold\n",
    "</br>: 무작위로 폴드화\n",
    "- StratifiedKFold\n",
    "</br>: 계층화를 유지하며 폴드화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b481ab13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document  label id\n",
       "0        A      1  a\n",
       "1        B      1  a\n",
       "2        C      0  b\n",
       "3        D      0  b\n",
       "4        E      1  c\n",
       "5        F      0  c\n",
       "6        G      0  d\n",
       "7        H      1  d"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "    # 일반 KFold, 계층화 KFold, 계층별 그룹화 KFold\n",
    "\n",
    "data = {\n",
    "    'document': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],   # 리뷰 글\n",
    "    'label': [1, 1, 0, 0, 1, 0, 0, 1],                      # 긍정/부정\n",
    "    'id': ['a', 'a', 'b', 'b', 'c', 'c', 'd', 'd']          # 작성자 ID - 각 작성자마다 글 2개\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b148cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['document']\n",
    "Y = df['label']\n",
    "groups = df['id']\n",
    "\n",
    "# 일반적인 KFold\n",
    "k_folds = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "# 계층화 KFold\n",
    "s_folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "# 계층별 그룹화 KFold\n",
    "sg_folds = StratifiedGroupKFold(n_splits=2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "75bf46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 KFold\n",
    "# for x_idx, y_idx in k_folds.split(X, Y):\n",
    "#     print(df.loc[x_idx])\n",
    "#     print(df.loc[y_idx])\n",
    "#     break     # 첫 번째만 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f83d2b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  document  label id\n",
      "1        B      1  a\n",
      "3        D      0  b\n",
      "6        G      0  d\n",
      "7        H      1  d\n",
      "  document  label id\n",
      "0        A      1  a\n",
      "2        C      0  b\n",
      "4        E      1  c\n",
      "5        F      0  c\n"
     ]
    }
   ],
   "source": [
    "# 계층화 KFold\n",
    "for x_idx, y_idx in s_folds.split(X, Y):\n",
    "    print(df.loc[x_idx])\n",
    "    print(df.loc[y_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c3cc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  document  label id\n",
      "4        E      1  c\n",
      "5        F      0  c\n",
      "6        G      0  d\n",
      "7        H      1  d\n",
      "  document  label id\n",
      "0        A      1  a\n",
      "1        B      1  a\n",
      "2        C      0  b\n",
      "3        D      0  b\n"
     ]
    }
   ],
   "source": [
    "# 계층별 그룹화 KFold\n",
    "for x_idx, y_idx in sg_folds.split(X, Y, groups):\n",
    "    print(df.loc[x_idx])\n",
    "    print(df.loc[y_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38fd50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8b4d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네이버 영화 리뷰 (rating_train.txt)\n",
    "# pandas를 이용하여 txt 파일 로드\n",
    "# 파일을 확인해보면, 데이터는 tab 으로 분리되어 있다.\n",
    "df = pd.read_csv('../data/ratings_train.txt', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c4ea16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# 정보 확인\n",
    "df.info()\n",
    "\n",
    "# document 컬럼에 5개의 결측치 존재\n",
    "# 전체 데이터가 15만 개이므로 결측치를 삭제해도 무방"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06d4c9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149995 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[149995 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "# case 1 - isna() + any() : 인덱스의 조건식으로 해당 조건을 부정하여 사용\n",
    "df.loc[~df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0583d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2 - dropna()\n",
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "102add2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "document\n",
       "굿                                                181\n",
       "good                                              92\n",
       "최고                                                85\n",
       "쓰레기                                               79\n",
       "별로                                                66\n",
       "                                                ... \n",
       "굿바이 레닌 표절인것은 이해하는데 왜 뒤로 갈수록 재미없어지냐                 1\n",
       "이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드!!♥      1\n",
       "약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.                 1\n",
       "나름 심오한 뜻도 있는 듯. 그냥 학생이 선생과 놀아나는 영화는 절대 아님          1\n",
       "흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나                  1\n",
       "Name: count, Length: 146182, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document에 중복되는 문장이 있다면 하나만 두고 나머지는 제거\n",
    "# 중복 데이터 존재 여부 확인\n",
    "df['document'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "296a7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 데이터를 제거한 뒤 행의 개수: 3813\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 제거\n",
    "# drop_duplicates()\n",
    "\n",
    "# 제거하기 전의 데이터 개수\n",
    "before = len(df)\n",
    "\n",
    "df = df.drop_duplicates(['document']).reset_index(drop=True)    # 인덱스 리셋 + 기존 인덱스 제거\n",
    "after = len(df)\n",
    "\n",
    "print(\"중복 데이터를 제거한 뒤 행의 개수:\", before - after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d0c0495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182\n"
     ]
    }
   ],
   "source": [
    "# id 컬럼의 중복 확인\n",
    "# unique() 를 이용해 id 컬럼의 유일한 데이터들의 길이 확인\n",
    "print(len( df['id'].unique() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4ef22b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n",
    "\n",
    "# df의 길이와 같으니 id 컬럼에 중복 없음\n",
    "# = 한 아이디 당 하나의 글을 작성했다.\n",
    "# -> 중복이 있으면 데이터를 나눌 때 계층화 KFold가 아닌 계층별 그룹화 KFold를 사용했어야 하는데,\n",
    "#    중복이 없으니 라벨에 대한 데이터의 균형도만 맞춰주면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f82adbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    73342\n",
       "1    72840\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 컬럼의 데이터 개수 확인\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c640f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation, test 데이터셋으로 약 8:1:1 분할\n",
    "# label의 비율에 맞게 분할\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn에는 3개의 데이터셋으로 나눠주는 함수가 존재하지 않으므로 traia_test_split을 2번 사용\n",
    "\n",
    "X = df['document'].values\n",
    "Y = df['label'].values\n",
    "\n",
    "# test 데이터셋 10%\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state= 42, stratify=Y\n",
    ")\n",
    "# validation 데이터셋 약 11% (label 데이터의 비율에 맞게)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.11, random_state= 42, stratify=Y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0107c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.09946505041661\n",
      "9.89998768658248\n",
      "10.000547263000916\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 분할 정도를 확인\n",
    "print( len(X_train) / len(X) * 100 )\n",
    "print( len(X_val) / len(X) * 100 )\n",
    "print( len(X_test) / len(X) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8e01e5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    58746\n",
      "1    58345\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(Y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd246301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7261\n",
      "1    7211\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(Y_val).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ac5269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold': 0,\n",
       "  'tr_idx': array([     0,      2,      3, ..., 117083, 117086, 117090],\n",
       "        shape=(58545,)),\n",
       "  'va_idx': array([     1,      7,      8, ..., 117087, 117088, 117089],\n",
       "        shape=(58546,))},\n",
       " {'fold': 1,\n",
       "  'tr_idx': array([     1,      7,      8, ..., 117087, 117088, 117089],\n",
       "        shape=(58546,)),\n",
       "  'va_idx': array([     0,      2,      3, ..., 117083, 117086, 117090],\n",
       "        shape=(58545,))}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계층 폴드화\n",
    "# : 학습 데이터를 분할/학습하여 일반적인 성능을 나타냄\n",
    "# 성능을 보기 위해 기본적으로 필요한 과정으로, 폴드화, 하이퍼 파라미터 탐색과 함께 사용\n",
    "folds = []\n",
    "\n",
    "# fold에는 0, 1, 2, 3, ...\n",
    "# enumerate() : 데이터를 리스트에서의 위치와 값으로 나눠 반환\n",
    "# s_folds.split(X_train, Y_train) : 결과 값이 ( (tr_idx, va_idx) ) 형태\n",
    "for fold, (tr_idx, va_idx) in enumerate( s_folds.split(X_train, Y_train) ):\n",
    "    folds.append(\n",
    "        {\n",
    "        'fold': fold,\n",
    "        'tr_idx': tr_idx,\n",
    "        'va_idx': va_idx\n",
    "        }\n",
    "    )\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "961dec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29373\n",
       "1    29172\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folds의 첫 번째 데이터에서 tr_idx로 Y_train의 0, 1 비율 확인\n",
    "test_idx = folds[0]['tr_idx']\n",
    "pd.Series(Y_train[test_idx]).value_counts()\n",
    "\n",
    "# 거의 1:1\n",
    "# 데이터 불균형 문제 거의 사라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ca4e3",
   "metadata": {},
   "source": [
    "---\n",
    "# 단어의 토큰화\n",
    "- 문장을 단어로 잘라준다.\n",
    "    - 공백을 기준으로 문자를 자른다.\n",
    "        - 영문에서는 사용 가능, 한글에서는 의미가 소실되는 경우 발생\n",
    "    - 형태소를 사용하여 문자를 나눈다.\n",
    "        - 국어 사전을 로드하여 단어별로 나눠준다.\n",
    "        - 대부분 반복문 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e4ea05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백을 기반으로 데이터를 나눈다.\n",
    "text = '나는 학교에 간다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c9d23fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나는', '학교에', '간다']\n"
     ]
    }
   ],
   "source": [
    "tokens = text.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f6427bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '학교', '에', '간다']\n",
      "[('나', 'Noun'), ('는', 'Josa'), ('학교', 'Noun'), ('에', 'Josa'), ('간다', 'Noun')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(text))\n",
    "print(okt.pos(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8950b262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'Noun'), ('는', 'Josa'), ('학교', 'Noun'), ('에', 'Josa'), ('간다', 'Noun')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos = okt.pos(text)\n",
    "text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95a5e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('나', 'Noun'), ('학교', 'Noun'), ('에', 'Josa'), ('간다', 'Noun')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos.remove( ('는', 'Josa') )\n",
    "# 하나씩 정리하는 방법 (매우 귀찮으므로 비추)\n",
    "text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a5220ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나\n",
      "학교\n",
      "간다\n"
     ]
    }
   ],
   "source": [
    "# 반복문을 이용하여 각 원소들을 대입해 실행\n",
    "for t in text_pos:\n",
    "    # print(t)\n",
    "    # t는 tuple의 형태 -> 조건: 두 번째 값이 'Josa'가 아니라면\n",
    "    if t[1] != 'Josa':\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c70391c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나', '학교', '간다']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d1ca5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이런 감동...삶의 희망이 된다'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okt 로드한 데이터를 이용하여 Okt 형태소 분석\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a89c0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이런', '감동', '...', '삶', '의', '희망이', '된다']\n",
      "['초등학교', '때', '이', '거', '200', '번', '받음', '..', '정말', '짱']\n",
      "['아이엠', '옴티머', '스프', '라임']\n",
      "['나', '만', '재밋', '게', '봤나']\n",
      "['최고', '의', '영화', '평점', '1', '점주', '는', '초딩', '들', '은', '대체', '뭐', '냐', '?', '요새', '한국', '영화', '들', '보다', '훨', '낫다', '.', '영화', '보고', '10년', '넘게', '기억', '에', '남았던', '명작', '이다', '.']\n"
     ]
    }
   ],
   "source": [
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    _pos = okt.morphs(t)\n",
    "    print(_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d62770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Korpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf792116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Korpora import Korpora\n",
    "# data = Korpora.load('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b9834ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b2030baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece 모듈을 이용하여 형태소 분석\n",
    "# 모델 학습\n",
    "# train txt, test txt 파일을 모두 로드하여 학습에 대입\n",
    "df_tr = pd.read_csv('../data/ratings_train.txt', sep='\\t').dropna()\n",
    "df_te = pd.read_csv('../data/ratings_test.txt', sep='\\t').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c525f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 개의 데이터프레임을 단순 행결합(union 결합)\n",
    "total_df = pd.concat( [df_tr['document'], df_te['document']], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6207ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 199992 entries, 0 to 199991\n",
      "Series name: document\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "199992 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4f62f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 학습시키기 전에 파일로 미리 저장\n",
    "total_df.to_csv('test.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "63cfd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 생성\n",
    "import sentencepiece as spm\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input= 'test.txt',              # 학습에서 사용할 텍스트 파일\n",
    "    model_prefix = 'ko_unigram',    # unigram: 한글에 적합한 형태 (한 단어씩 잘라서 표현)\n",
    "    vocab_size = 8000,              # 단어 사전의 크기 (모델의 크기) - 일반적으로 8000, 16000, 32000 - 클수록 정확도 올라가고 계산량 많아짐\n",
    "    model_type = 'unigram',         # 토큰의 생성 방식\n",
    "    character_coverage = 0.9995,    # 학습에 포함할 문자의 종류 비율 (1.0 - 모든 문자 종류 포함, 0.9995 - 한글, 영문, 숫자 포함)\n",
    "    input_sentence_size = 1000000,  # 학습 문장을 샘플링 (모든 데이터를 사용하는 게 가장 좋지만, 시간 상의 문제로 일부만 샘플링하여 사용)\n",
    "    shuffle_input_sentence = True   # 샘플링 시 문자의 순서를 섞어 사용 - 모델이 특정 성향에 편향되는 것을 방지\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c4585",
   "metadata": {},
   "source": [
    "언어 모델\n",
    "- unigram : 단어 단위. BERT, KoGPT 등에서 사용 (한국어에 적합)\n",
    "- bpe : GPT-2 에서 사용\n",
    "- char : 문자 단위 (정보가 너무 짧게 쪼개짐)\n",
    "- word : 단어 단위 (한국어에 부적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "254f48b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁나는', '▁학교', '에', '▁간다']\n"
     ]
    }
   ],
   "source": [
    "# 생성된 모델을 이용하여 형태소 분석\n",
    "sp = spm.SentencePieceProcessor()\n",
    "\n",
    "# 생성된 모델을 로드\n",
    "sp.load('ko_unigram.model')\n",
    "text = '나는 학교에 간다'\n",
    "print(sp.encode(text, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de4e6efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁\n"
     ]
    }
   ],
   "source": [
    "# ▁ 특수기호는 키보드 입력이 불가함\n",
    "char = '\\u2581'\n",
    "print(char)\n",
    "# 이렇게 안 하고 그냥 복붙해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe0750af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁이런', '▁감동', '...', '삶', '의', '▁희망', '이', '▁된다']\n",
      "['▁초', '등', '학교', '▁때', '▁이거', '▁', '200', '번', '▁받', '음', '..', '▁정말', '▁짱']\n",
      "['▁아이', '엠', '옴', '티', '머', '스', '프', '라', '임']\n",
      "['▁나만', '▁재밋게', '▁봤', '나']\n",
      "['▁최고의', '▁영화', '▁평점', '1', '점주는', '▁초딩', '들은', '▁대체', '▁뭐냐', '?', '▁요새', '▁한국영화', '들', '보다', '▁훨', '▁낫다', '.', '▁영화보고', '▁10', '년', '넘', '게', '▁기억에', '▁남았', '던', '▁명작이다', '.']\n"
     ]
    }
   ],
   "source": [
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(sp.encode(t, out_type=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "deb8a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt와 같은 형태 (한글에 적합)\n",
    "from konlpy.tag import Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d13dd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "62659d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '학교', '에', '간다']\n",
      "[('나', 'NP'), ('는', 'JX'), ('학교', 'NNG'), ('에', 'JKB'), ('간다', 'NNP')]\n",
      "['학교', '간다']\n"
     ]
    }
   ],
   "source": [
    "print(komoran.morphs(text))     # 형태소 나열\n",
    "print(komoran.pos(text))        # ( 형태소, 동사 ) 튜플 나열\n",
    "print(komoran.nouns(text))      # 명사만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13d1ec",
   "metadata": {},
   "source": [
    "### Komoran 동사를 일반적으로 사용하는 것들\n",
    "- 감성/의도 분석/리뷰 (가장 일반적)\n",
    "    - NNG (일반명사), NNP (고유명사), VV (동사), VA (형용사), MAG (일반부사), SL (외국어)\n",
    "- 명사 기반의 분류 (문서에 대한 분류 작업)\n",
    "    - NNG (일반명사), NNP (고유명사), NP (대명사), NR (수사)\n",
    "- 의미가 있는 단어를 최대한 포함하고 싶은 경우\n",
    "    - NNG (일반명사), NNP (고유명사), VV (동사), VA (형용사), MAG (일반부사), MAJ (접속부사), IC (감탄사), SL (외국어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3aee53dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['감동', '삶', '희망', '되']\n",
      "['초등학교', '때', '받']\n",
      "[]\n",
      "['보']\n",
      "['최고', '영화', '평점', '주', '초딩', '대체', '요새', '한국', '영화', '낫', '영화', '넘', '기억', '남', '명작']\n"
     ]
    }
   ],
   "source": [
    "# 사용할 형태소의 종류\n",
    "allow_pos = ['NNG', 'NNP', 'VV', 'VA']\n",
    "\n",
    "# 선택한 형태소를 추출하기 위한 함수를 정의\n",
    "def komoran_tokenize(text):\n",
    "    # 선택한 형태소만 저장하는 빈 리스트를 생성\n",
    "    result = []\n",
    "    for morph, pos in komoran.pos(text):\n",
    "        if pos in allow_pos:\n",
    "            result.append(morph)\n",
    "    return result\n",
    "\n",
    "for idx, t in enumerate(X_train):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(komoran_tokenize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4601b860",
   "metadata": {},
   "source": [
    "# 벡터화\n",
    "- 토큰화 작업에서 단어들을 추출했다면 해당 단어들을 숫자형으로 변환\n",
    "    - 숫자 형태로 변환하는 이유 : 컴퓨터가 숫자로만 연산 가능\n",
    "- 숫자 형태로 변환한 데이터를 학습 데이터로 이용, 정답은 label\n",
    "</br>⇒ 데이터로 규칙을 생성해가는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f289f9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding - 하나의 리뷰에서 특정 단어가 포함되어 있는가?\n",
    "df = pd.read_csv('../data/ratings_train.txt', sep='\\t').dropna()\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da316b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  label\n",
       "0                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f2268b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체의 텍스트를 이용해 학습하여 단어를 습득한 뒤, 해당하는 단어들이 리뷰에 포함되어 있는지 확인\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9aa26685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 71 stored elements and shape (10, 70)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 객체 생성\n",
    "# 이진으로 나눠 존재 여부만 파악\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# 학습한 뒤 변환 (학습할 데이터 대입)\n",
    "# 데이터는 document의 데이터 중 10개\n",
    "X = vectorizer.fit_transform(df['document'].head(10))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd55d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1학년생인' '3세부터' '8살용영화' 'ㅋㅋㅋ' '가볍지' '가족도없다' '감금만반복반복' '걸음마' '교도소' '그것보단'\n",
      " '긴장감을' '길들여져' '길용우' '납치' '낫겟다' '낮은건데' '너무' '너무나도' '너무재밓었다그래서보는것을추천한다'\n",
      " '늙어보이기만' '더빙' '던스트가' '돋보였던' '몇안되는' '목소리' '반개도' '발로해도' '별반개도' '볼만한데'\n",
      " '사이몬페그의' '살려내지못했다' '솔직히' '스파이더맨에서' '아까움' '아깝다' '않구나' '액션이' '없는데도' '없다'\n",
      " '연기가' '연기못하는사람만모엿네' '연기생활이몇년인지' '영화' '오버연기조차' '왜케' '욕나온다' '원작의' '이드라마는'\n",
      " '이뻐보였다' '이야기구먼' '이응경' '익살스런' '있나' '있는' '재미' '재미는' '정말' '제대로' '조정' '진짜'\n",
      " '짜증나네요' '초등학교' '초딩영화줄' '커스틴' '평점' '평점이' '포스터보고' '했던' '헐리우드식' '화려함에만']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습한 단어들이 무엇인지 출력 (단어 사전)\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab)    # 인덱스 10개\n",
    "len(vocab)      # 피쳐 70개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34d7196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      "  0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# get_feature_names_out() 의 단어를 포함하고 있는지 확인\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "37bee7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "020bfdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Okt + CounterVectorizer 같이 사용 -> 토큰화 + 벡터화\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# 형태소 변환 함수 정의\n",
    "def okt_tokenize(text):\n",
    "    # 특정 형태의 단어들만 추출\n",
    "    # 명사, 동사, 형용사\n",
    "    select_pos = ['Noun', 'Verb', 'Adjective']\n",
    "    # pos() 함수 - ( 단어, 형태 ) 를 출력\n",
    "    # result = okt.morphs(text)\n",
    "    result = [\n",
    "        word for word, pos in okt.pos(text) if pos in select_pos\n",
    "    ]\n",
    "    # 아래와 같이 작동\n",
    "    # result2 = []\n",
    "    # word for word, pos in okt.pos(text):\n",
    "    #     if pos in select_pos:\n",
    "    #         result2.append(word)\n",
    "    return result\n",
    "\n",
    "\n",
    "# CounterVectorizer 생성\n",
    "vectorizer_okt = CountVectorizer(\n",
    "    tokenizer= okt_tokenize,\n",
    "    lowercase= False,    # 국문에선 괜찮지만 영문에서는 소문자로 통일 필요\n",
    "    binary= True\n",
    ")\n",
    "\n",
    "x_okt = vectorizer_okt.fit_transform(df['document'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ca15d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가볍지' '교도소' '구먼' '늙어' '다그' '더빙' '던스트' '돋보였던' '래서' '목소리' '몬페' '무재' '밓었'\n",
      " '보고' '보는것을' '보였다' '보이기만' '솔직히' '스파이더맨' '않구나' '없다' '연기' '영화' '오버' '의' '이뻐'\n",
      " '이야기' '익살스런' '재미' '조정' '줄' '진짜' '짜증나네요' '초딩' '추천' '커스틴' '평점' '포스터' '했던'\n",
      " '흠']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer_okt.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4e6c8822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 1 0 0\n",
      "  0 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      "  1 0 0 0]\n",
      " [0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      "  0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_okt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "efc66a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가볍지</th>\n",
       "      <th>교도소</th>\n",
       "      <th>구먼</th>\n",
       "      <th>늙어</th>\n",
       "      <th>다그</th>\n",
       "      <th>더빙</th>\n",
       "      <th>던스트</th>\n",
       "      <th>돋보였던</th>\n",
       "      <th>래서</th>\n",
       "      <th>목소리</th>\n",
       "      <th>...</th>\n",
       "      <th>줄</th>\n",
       "      <th>진짜</th>\n",
       "      <th>짜증나네요</th>\n",
       "      <th>초딩</th>\n",
       "      <th>추천</th>\n",
       "      <th>커스틴</th>\n",
       "      <th>평점</th>\n",
       "      <th>포스터</th>\n",
       "      <th>했던</th>\n",
       "      <th>흠</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   가볍지  교도소  구먼  늙어  다그  더빙  던스트  돋보였던  래서  목소리  ...  줄  진짜  짜증나네요  초딩  추천  \\\n",
       "0    0    0   0   0   0   1    0     0   0    1  ...  0   1      1   0   0   \n",
       "1    1    0   0   0   0   0    0     0   0    0  ...  1   0      0   1   0   \n",
       "2    0    0   0   0   1   0    0     0   1    0  ...  0   0      0   0   1   \n",
       "3    0    1   1   0   0   0    0     0   0    0  ...  0   0      0   0   0   \n",
       "4    0    0   0   1   0   0    1     1   0    0  ...  0   0      0   0   0   \n",
       "\n",
       "   커스틴  평점  포스터  했던  흠  \n",
       "0    0   0    0   0  0  \n",
       "1    0   0    1   0  1  \n",
       "2    0   0    0   0  0  \n",
       "3    0   1    0   0  0  \n",
       "4    1   0    0   1  0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 보기 편하게 변환\n",
    "pd.DataFrame(\n",
    "    x_okt.toarray(),\n",
    "    columns= vectorizer_okt.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710ebcf",
   "metadata": {},
   "source": [
    "실제로는 one-hot-encoding은 수치형 데이터에 범주가 들어가있을 때 더 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a647a8",
   "metadata": {},
   "source": [
    "---\n",
    "# 단어의 중요도를 벡터화\n",
    ": 단어의 빈도와 희소성을 결합하여 단어의 중요도를 수치화하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0618fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4492de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 형태소 분석 함수 생성\n",
    "okt = Okt()\n",
    "\n",
    "def okt_tokenize(text):\n",
    "    return okt.morphs(text)\n",
    "\n",
    "vectorizer_okt = TfidfVectorizer(\n",
    "    tokenizer = okt_tokenize,   # 토큰화 작업\n",
    "    ngram_range = (1, 2),       # 단어의 범위 = unigram (단어 1개씩 독립) -> 결과에 가장 영향이 큰 매개변수!\n",
    "    min_df = 1,                 # 최소 등장 단어의 개수\n",
    "    lowercase = False           # 모든 문자를 소문자로 변경 (국문에서는 의미 X)    # 국문만 있다고 가정하고, 효율적으로 사용하기 위해 False로 둠\n",
    ")\n",
    "\n",
    "# 사용할 샘플 데이터\n",
    "df = pd.read_csv(\"../data/ratings_train.txt\", sep='\\t').dropna()\n",
    "texts = df['document'].head(5)\n",
    "\n",
    "x_okt = vectorizer_okt.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "664ed5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어들의 목록 생성\n",
    "vocab_okt = vectorizer_okt.get_feature_names_out()\n",
    "len(vocab_okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d57276b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.2472117 , 0.        , 0.30641253,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30641253, 0.30641253, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30641253, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30641253, 0.30641253, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30641253, 0.30641253, 0.30641253, 0.30641253, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20285256, 0.20285256, 0.20285256, 0.20285256,\n",
       "        0.        , 0.        , 0.        , 0.20285256, 0.20285256,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20285256, 0.20285256, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20285256, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.16366017, 0.        , 0.20285256,\n",
       "        0.16366017, 0.        , 0.20285256, 0.20285256, 0.20285256,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20285256, 0.20285256, 0.20285256, 0.20285256,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.20285256,\n",
       "        0.20285256, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20285256, 0.20285256, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20285256, 0.20285256],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24253563, 0.24253563, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24253563,\n",
       "        0.24253563, 0.24253563, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24253563, 0.24253563,\n",
       "        0.        , 0.        , 0.        , 0.24253563, 0.24253563,\n",
       "        0.24253563, 0.24253563, 0.        , 0.        , 0.24253563,\n",
       "        0.24253563, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24253563, 0.24253563, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24253563,\n",
       "        0.24253563, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.34715929, 0.21514749, 0.        ,\n",
       "        0.21514749, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21514749, 0.21514749, 0.21514749, 0.21514749, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21514749, 0.21514749, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21514749, 0.21514749, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21514749, 0.21514749,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21514749,\n",
       "        0.21514749, 0.        , 0.        , 0.21514749, 0.21514749,\n",
       "        0.21514749, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21514749, 0.21514749, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.15375187, 0.15375187, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30750374, 0.15375187, 0.15375187, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15375187,\n",
       "        0.15375187, 0.        , 0.        , 0.15375187, 0.15375187,\n",
       "        0.        , 0.        , 0.15375187, 0.15375187, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15375187,\n",
       "        0.15375187, 0.15375187, 0.15375187, 0.        , 0.        ,\n",
       "        0.        , 0.15375187, 0.15375187, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15375187, 0.15375187, 0.15375187, 0.15375187,\n",
       "        0.15375187, 0.        , 0.        , 0.15375187, 0.15375187,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15375187, 0.15375187, 0.12404604, 0.15375187, 0.        ,\n",
       "        0.12404604, 0.15375187, 0.        , 0.        , 0.        ,\n",
       "        0.15375187, 0.15375187, 0.15375187, 0.15375187, 0.        ,\n",
       "        0.        , 0.15375187, 0.15375187, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15375187, 0.15375187,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15375187, 0.15375187, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어들 간의 중요도\n",
    "x_okt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "87476999",
   "metadata": {},
   "outputs": [],
   "source": [
    "komoran = Komoran()\n",
    "\n",
    "# 품사 지정\n",
    "allow_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG', 'SL']\n",
    "# 필터용 언어 (포함시키지 않을 언어)\n",
    "stop_word = ['하다', '되다']\n",
    "\n",
    "def komoran_tokenize(text):\n",
    "    tokens = []\n",
    "    for morph, pos in komoran.pos(text):\n",
    "        # text: 문장\n",
    "        # morph: 단어\n",
    "        # pos: 형태소의 형태(품사)\n",
    "        # 조건 1. pos가 allow_pos에 포함되어 있다.\n",
    "        # 조건 2. morph가 stop_word에 포함되어 있지 않다.\n",
    "        if pos in allow_pos and morph not in stop_word:\n",
    "            tokens.append(morph)\n",
    "    return tokens\n",
    "\n",
    "vectorizer_komoran = TfidfVectorizer(\n",
    "    tokenizer = okt_tokenize,   # 토큰화 작업\n",
    "    ngram_range = (1, 1),       # 단어의 범위 = unigram (단어 1개씩 독립) -> 결과에 가장 영향이 큰 매개변수!\n",
    "    min_df = 1,                 # 최소 등장 단어의 개수\n",
    "    lowercase = False           # 모든 문자를 소문자로 변경 (국문에서는 의미 X)    # 국문만 있다고 가정하고, 효율적으로 사용하기 위해 False로 둠\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b1f94687",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_komoran = vectorizer_komoran.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6c15e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "<bound method CountVectorizer.get_feature_names_out of TfidfVectorizer(lowercase=False,\n",
      "                tokenizer=<function okt_tokenize at 0x000001C0213ADA80>)>\n"
     ]
    }
   ],
   "source": [
    "# 단어들의 목록 확인\n",
    "print(len(vectorizer_komoran.get_feature_names_out()))\n",
    "print(vectorizer_komoran.get_feature_names_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ca87f6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.33939315, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.        , 0.        , 0.        , 0.42066906,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.42066906, 0.42066906, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.28511174, 0.28511174, 0.        ,\n",
       "        0.28511174, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28511174, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.28511174, 0.        , 0.        , 0.23002636,\n",
       "        0.23002636, 0.28511174, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.28511174, 0.28511174,\n",
       "        0.        , 0.        , 0.28511174, 0.        , 0.        ,\n",
       "        0.        , 0.28511174, 0.        , 0.        , 0.28511174],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.33333333, 0.33333333, 0.        , 0.33333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ],\n",
       "       [0.        , 0.47369076, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29356375, 0.29356375, 0.        , 0.        ,\n",
       "        0.        , 0.29356375, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29356375, 0.        ,\n",
       "        0.        , 0.        , 0.29356375, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29356375,\n",
       "        0.        , 0.29356375, 0.29356375, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29356375, 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.21175308, 0.        , 0.        , 0.        , 0.42350615,\n",
       "        0.        , 0.        , 0.        , 0.21175308, 0.        ,\n",
       "        0.21175308, 0.        , 0.21175308, 0.        , 0.        ,\n",
       "        0.        , 0.21175308, 0.21175308, 0.        , 0.        ,\n",
       "        0.21175308, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21175308, 0.21175308, 0.21175308, 0.        , 0.21175308,\n",
       "        0.        , 0.        , 0.        , 0.21175308, 0.17084105,\n",
       "        0.17084105, 0.        , 0.21175308, 0.21175308, 0.        ,\n",
       "        0.21175308, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21175308,\n",
       "        0.        , 0.        , 0.        , 0.21175308, 0.        ]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_komoran.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "56ffb81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>....</th>\n",
       "      <th>가</th>\n",
       "      <th>가볍지</th>\n",
       "      <th>교도소</th>\n",
       "      <th>구먼</th>\n",
       "      <th>그</th>\n",
       "      <th>너</th>\n",
       "      <th>...</th>\n",
       "      <th>진짜</th>\n",
       "      <th>짜증나네요</th>\n",
       "      <th>초딩</th>\n",
       "      <th>추천</th>\n",
       "      <th>커스틴</th>\n",
       "      <th>평점</th>\n",
       "      <th>포스터</th>\n",
       "      <th>한</th>\n",
       "      <th>했던</th>\n",
       "      <th>흠</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420669</td>\n",
       "      <td>0.420669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !        ..       ...      ....         가       가볍지       교도소  \\\n",
       "0  0.000000  0.339393  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.285112  0.285112  0.000000  0.285112  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.473691  0.000000  0.000000  0.000000  0.000000  0.293564   \n",
       "4  0.211753  0.000000  0.000000  0.000000  0.423506  0.000000  0.000000   \n",
       "\n",
       "         구먼         그         너  ...        진짜     짜증나네요        초딩        추천  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.420669  0.420669  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.285112  0.000000   \n",
       "2  0.000000  0.000000  0.333333  ...  0.000000  0.000000  0.000000  0.333333   \n",
       "3  0.293564  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.211753  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        커스틴        평점       포스터         한        했던         흠  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.285112  0.000000  0.000000  0.285112  \n",
       "2  0.000000  0.000000  0.000000  0.333333  0.000000  0.000000  \n",
       "3  0.000000  0.293564  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.211753  0.000000  0.000000  0.000000  0.211753  0.000000  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran_df = pd.DataFrame(x_komoran.toarray(), columns=vectorizer_komoran.get_feature_names_out())\n",
    "komoran_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "71d7cab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>..</th>\n",
       "      <th>...</th>\n",
       "      <th>....</th>\n",
       "      <th>가</th>\n",
       "      <th>가볍지</th>\n",
       "      <th>교도소</th>\n",
       "      <th>구먼</th>\n",
       "      <th>그</th>\n",
       "      <th>너</th>\n",
       "      <th>...</th>\n",
       "      <th>짜증나네요</th>\n",
       "      <th>초딩</th>\n",
       "      <th>추천</th>\n",
       "      <th>커스틴</th>\n",
       "      <th>평점</th>\n",
       "      <th>포스터</th>\n",
       "      <th>한</th>\n",
       "      <th>했던</th>\n",
       "      <th>흠</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          !        ..       ...      ....         가       가볍지       교도소  \\\n",
       "0  0.000000  0.339393  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.285112  0.285112  0.000000  0.285112  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.473691  0.000000  0.000000  0.000000  0.000000  0.293564   \n",
       "4  0.211753  0.000000  0.000000  0.000000  0.423506  0.000000  0.000000   \n",
       "\n",
       "         구먼         그         너  ...     짜증나네요        초딩        추천       커스틴  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.420669  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.285112  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.333333  ...  0.000000  0.000000  0.333333  0.000000   \n",
       "3  0.293564  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.211753  0.000000  ...  0.000000  0.000000  0.000000  0.211753   \n",
       "\n",
       "         평점       포스터         한        했던         흠  label  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000      0  \n",
       "1  0.000000  0.285112  0.000000  0.000000  0.285112      1  \n",
       "2  0.000000  0.000000  0.333333  0.000000  0.000000      0  \n",
       "3  0.293564  0.000000  0.000000  0.000000  0.000000      0  \n",
       "4  0.000000  0.000000  0.000000  0.211753  0.000000      1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "komoran_df['label'] = df['label'].head(5)\n",
    "komoran_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
