{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb871b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6446f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/인터뷰/ckmk_d_bm_f_n_169087.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f8468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, info to answer\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   version      3 non-null      int64 \n",
      " 1   dataSet      3 non-null      object\n",
      " 2   rawDataInfo  2 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 96.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf42cca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>dataSet</th>\n",
       "      <th>rawDataInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>info</th>\n",
       "      <td>1</td>\n",
       "      <td>{'date': '20230116', 'occupation': 'BM', 'chan...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>1</td>\n",
       "      <td>{'raw': {'text': '지원자님께서 가지고 계신 나만의 스트레스 해소법이 ...</td>\n",
       "      <td>{'fileFormat': 'wav', 'fileSize': 664398, 'dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>1</td>\n",
       "      <td>{'raw': {'text': '저는 저 혼자 시간을 보내는 것을 우선적으로 하고요...</td>\n",
       "      <td>{'fileFormat': 'wav', 'fileSize': 1900238, 'du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          version                                            dataSet  \\\n",
       "info            1  {'date': '20230116', 'occupation': 'BM', 'chan...   \n",
       "question        1  {'raw': {'text': '지원자님께서 가지고 계신 나만의 스트레스 해소법이 ...   \n",
       "answer          1  {'raw': {'text': '저는 저 혼자 시간을 보내는 것을 우선적으로 하고요...   \n",
       "\n",
       "                                                rawDataInfo  \n",
       "info                                                    NaN  \n",
       "question  {'fileFormat': 'wav', 'fileSize': 664398, 'dur...  \n",
       "answer    {'fileFormat': 'wav', 'fileSize': 1900238, 'du...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5554b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_json을 통해 json파일을 로드했는데, 데이터 형태가 데이터프레임에 최적화되어 있지 않다.\n",
    "# -> 답변의 데이터, 답변의 요약 데이터를 추출 -> kobart 모델을 이용해서 요약 학습\n",
    "# 데이터 추출을 위해 json 파일을 dict 형태로 변환\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4b290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일을 로드해서 dict 형태로 변환\n",
    "# 방법 1\n",
    "with open(\"../data/인터뷰/ckmk_d_bm_f_n_169087.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0531cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2\n",
    "f2 = open(\"../data/인터뷰/ckmk_d_bm_f_n_169087.json\", 'r', encoding='utf-8')\n",
    "data2 = json.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40775bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f52ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c1d5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version': '1.0', 'dataSet': {'info': {'date': '20230116', 'occupation': 'BM', 'channel': 'MOCK', 'place': 'ONLINE', 'gender': 'FEMALE', 'ageRange': '-34', 'experience': 'NEW'}, 'question': {'raw': {'text': '지원자님께서 가지고 계신 나만의 스트레스 해소법이 있으신지 있으시다고 한다면 왜 그러한 방법으로 스트레스를 해소하려고 하셨는지 이야기해 주실 수 있으실까요', 'wordCount': 19}, 'emotion': [], 'intent': []}, 'answer': {'raw': {'text': '저는 저 혼자 시간을 보내는 것을 우선적으로 하고요. 예를 들어서 혼자 산책을 한다든지 아니면 혼자 카페를 간다든지 아니면 혼자 코인 노래방을 간다든지 해서 스트레스를 해소하는 편입니다. 물론 남들과 만나면서 시간을 보내는 것도 굉장히 좋아하지만요. 아무래도 내 혼자만의 시간이 있어야 어느 정도 생각 정리도 되고 그러면서 내 안에 있던 응어리도 절로 풀러지는 그런 것을 경험하게 되었습니다. 그리고 코인 노래방이나 이런 곳에 가면은 아무래도 제가 노래 부르는 것도 좋아하고 그리고 노래를 부르면서 그런 소리가 웅웅거리고 또 소리를 지른다는 거에 대해서 해소감도 있는 것 같고요. 그래서 저는 일단 혼자만의 시간을 보내는데 뭐 혼자서 노래방을 가거나 아니면 혼자서 카페를 가거나 그런 식으로 스트레스를 해소한다 라고 말씀을 드릴 수 있을 것 같습니다.', 'wordCount': 107}, 'emotion': [], 'intent': [{'text': '', 'expression': '', 'category': 'attitude'}], 'summary': {'text': '저는 혼자 시간을 보내는 것을 우선적으로 하며, 혼자 산책을 하거나 혼자 카페를 간다든지 또는 혼자 노래방을 간다든지 해서 스트레스를 해소하는 편입니다. 혼자의 시간이 있으면 생각 정리도 되고 제 안에 있던 응어리도 저절로 풀러지는 것을 경험하게 되었습니다.', 'wordCount': 36}}}, 'rawDataInfo': {'question': {'fileFormat': 'wav', 'fileSize': 664398, 'duration': 20760, 'samplingBit': 16, 'channelCount': 1, 'samplingRate': '16kHz', 'audioPath': '/Mock/01.Management/Female/New/ckmk_q_bm_f_n_169087.wav'}, 'answer': {'fileFormat': 'wav', 'fileSize': 1900238, 'duration': 59380, 'samplingBit': 16, 'channelCount': 1, 'samplingRate': '16kHz', 'audioPath': '/Mock/01.Management/Female/New/ckmk_a_bm_f_n_169087.wav'}}}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60323582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataSet': {'answer': {'emotion': [],\n",
      "                        'intent': [{'category': 'attitude',\n",
      "                                    'expression': '',\n",
      "                                    'text': ''}],\n",
      "                        'raw': {'text': '저는 저 혼자 시간을 보내는 것을 우선적으로 하고요. 예를 들어서 '\n",
      "                                        '혼자 산책을 한다든지 아니면 혼자 카페를 간다든지 아니면 혼자 코인 '\n",
      "                                        '노래방을 간다든지 해서 스트레스를 해소하는 편입니다. 물론 남들과 '\n",
      "                                        '만나면서 시간을 보내는 것도 굉장히 좋아하지만요. 아무래도 내 '\n",
      "                                        '혼자만의 시간이 있어야 어느 정도 생각 정리도 되고 그러면서 내 '\n",
      "                                        '안에 있던 응어리도 절로 풀러지는 그런 것을 경험하게 되었습니다. '\n",
      "                                        '그리고 코인 노래방이나 이런 곳에 가면은 아무래도 제가 노래 부르는 '\n",
      "                                        '것도 좋아하고 그리고 노래를 부르면서 그런 소리가 웅웅거리고 또 '\n",
      "                                        '소리를 지른다는 거에 대해서 해소감도 있는 것 같고요. 그래서 저는 '\n",
      "                                        '일단 혼자만의 시간을 보내는데 뭐 혼자서 노래방을 가거나 아니면 '\n",
      "                                        '혼자서 카페를 가거나 그런 식으로 스트레스를 해소한다 라고 말씀을 '\n",
      "                                        '드릴 수 있을 것 같습니다.',\n",
      "                                'wordCount': 107},\n",
      "                        'summary': {'text': '저는 혼자 시간을 보내는 것을 우선적으로 하며, 혼자 산책을 '\n",
      "                                            '하거나 혼자 카페를 간다든지 또는 혼자 노래방을 간다든지 '\n",
      "                                            '해서 스트레스를 해소하는 편입니다. 혼자의 시간이 있으면 '\n",
      "                                            '생각 정리도 되고 제 안에 있던 응어리도 저절로 풀러지는 '\n",
      "                                            '것을 경험하게 되었습니다.',\n",
      "                                    'wordCount': 36}},\n",
      "             'info': {'ageRange': '-34',\n",
      "                      'channel': 'MOCK',\n",
      "                      'date': '20230116',\n",
      "                      'experience': 'NEW',\n",
      "                      'gender': 'FEMALE',\n",
      "                      'occupation': 'BM',\n",
      "                      'place': 'ONLINE'},\n",
      "             'question': {'emotion': [],\n",
      "                          'intent': [],\n",
      "                          'raw': {'text': '지원자님께서 가지고 계신 나만의 스트레스 해소법이 있으신지 '\n",
      "                                          '있으시다고 한다면 왜 그러한 방법으로 스트레스를 해소하려고 '\n",
      "                                          '하셨는지 이야기해 주실 수 있으실까요',\n",
      "                                  'wordCount': 19}}},\n",
      " 'rawDataInfo': {'answer': {'audioPath': '/Mock/01.Management/Female/New/ckmk_a_bm_f_n_169087.wav',\n",
      "                            'channelCount': 1,\n",
      "                            'duration': 59380,\n",
      "                            'fileFormat': 'wav',\n",
      "                            'fileSize': 1900238,\n",
      "                            'samplingBit': 16,\n",
      "                            'samplingRate': '16kHz'},\n",
      "                 'question': {'audioPath': '/Mock/01.Management/Female/New/ckmk_q_bm_f_n_169087.wav',\n",
      "                              'channelCount': 1,\n",
      "                              'duration': 20760,\n",
      "                              'fileFormat': 'wav',\n",
      "                              'fileSize': 664398,\n",
      "                              'samplingBit': 16,\n",
      "                              'samplingRate': '16kHz'}},\n",
      " 'version': '1.0'}\n"
     ]
    }
   ],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96016e4d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## kobart 복습 \n",
    "1. 인터뷰 폴더 안에 있는 json 파일들을 로드 \n",
    "    - 답변에 대한 데이터들을 하나의 리스트로 생성 \n",
    "    - 답변 요약에 대한 데이터들을 하나의 리스트로 생성 \n",
    "2. 위에서 생성된 데이터들 중\n",
    "    - train 데이터는 처음 100개의 데이터\n",
    "    - validation 데이터는 마지막 10개의 데이터\n",
    "3. train, test 데이터를 DatasetDict 형태로 변환 \n",
    "4. tokenizer와 model을 로드하여 데이터를 학습하고 검증 \n",
    "    - input의 최대 사이즈 : 512\n",
    "    - output의 최대 사이즈 : 256\n",
    "5. test 데이터를 생성 : 원본 리스트의 200번째 데이터를 이용하여 요약을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b080e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일의 목록을 생성 \n",
    "import os \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "562fa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/인터뷰/\"\n",
    "file_list = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da98830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 또는\n",
    "file_list2 = glob(\"../data/인터뷰/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1ac4e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/인터뷰/ckmk_d_bm_f_n_169087.json\n"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    # os 라이브러리를 이용하여 파일의 목록을 불러왔을때\n",
    "    path = file_path + file\n",
    "    print(path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff633e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid control character at: line 23 column 135 (char 755)\n",
      "Invalid control character at: line 23 column 571 (char 1132)\n",
      "Invalid control character at: line 23 column 433 (char 1029)\n"
     ]
    }
   ],
   "source": [
    "# answer의 원문과 요약 텍스트들을 저장할수 있는 빈 리스트 생성\n",
    "answers, summarys = [], []\n",
    "for file in file_list2:\n",
    "    # print(file)\n",
    "    # break\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            dict_data = json.load(f)\n",
    "            answer = dict_data['dataSet']['answer']['raw']['text']\n",
    "            summary = dict_data['dataSet']['answer']['summary']['text']\n",
    "            answers.append(answer)\n",
    "            summarys.append(summary)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c731acc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12801"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ec55441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 걸리는 시간이 길기때문에 일부분만 확인\n",
    "train_docs = answers[ : 100]\n",
    "train_sums = summarys[ : 100]\n",
    "valid_docs = answers[-10 : ]\n",
    "valid_sums = summarys[-10 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86f9d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "print( len(train_docs), len(train_sums) )\n",
    "print( len(valid_docs), len(valid_sums) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143ca916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainer, \n",
    "    Seq2SeqTrainingArguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9822d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gogamza/kobart-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81963cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DatasetDict 생성 \n",
    "raw_ds = DatasetDict(\n",
    "    {\n",
    "        'train' : Dataset.from_dict(\n",
    "            {\n",
    "                'document' : train_docs, \n",
    "                'summary' : train_sums\n",
    "            }\n",
    "        ), \n",
    "        'validation' : Dataset.from_dict(\n",
    "            {\n",
    "                'document' : valid_docs, \n",
    "                'summary' : valid_sums\n",
    "            }\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "926b74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n",
      "You passed `num_labels=3` which is incompatible to the `id2label` map of length `2`.\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저, 모델 로드 \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast = True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# 입 출력 길이 설정 \n",
    "max_input_len = 512\n",
    "max_target_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04a34ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_fn(batch):\n",
    "    inputs = tokenizer(\n",
    "        batch['document'], \n",
    "        max_length = max_input_len, \n",
    "        padding = 'max_length', \n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch['summary'], \n",
    "            max_length = max_target_len, \n",
    "            padding = 'max_length', \n",
    "            truncation = True\n",
    "        )\n",
    "    # labels의 input_ids에서 padding_token을 -100으로 변경 -> inputs['labels'] 대입\n",
    "    labels_ids = np.array(labels['input_ids'])\n",
    "    labels_ids[labels_ids == tokenizer.pad_token_id ] = -100\n",
    "    inputs['labels'] = labels_ids.tolist()\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b40e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/100 [00:00<?, ? examples/s]c:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 748.36 examples/s]\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 765.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_ds = raw_ds.map(\n",
    "    tok_fn, batched= True, remove_columns= ['document', 'summary']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "375724c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer= tokenizer,\n",
    "    model= model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01811b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics 지정\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be64d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    # 디코더의 역할: vocab의 인덱스로 구성된 리스트를 다시 문자 형태로 변환\n",
    "    #   예: preds = [13, 17, 102, ...(사전 vocab=['A', 'B', ...]에서 해당 값의 위치)] 처럼 labels 데이터와 같은 형태로 만들어질 것.\n",
    "    # padding 토큰을 무시하기 위해 -100으로 구성했던 것을, 원래의 id 값으로 전환\n",
    "    labels = np.where(\n",
    "        labels != -100, labels, tokenizer.pad_token_id\n",
    "    )\n",
    "    # 텍스트 디코딩\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True)  # 특수 토큰들은 디코드하지 않음\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # 문장의 좌우에 공백이 존재하는 경우 다른 값으로 측정하기 때문에 좌우 공백 제거\n",
    "    pred_str = [ doc.strip() for doc in pred_str ]\n",
    "    label_str = [ doc.strip() for doc in label_str ]\n",
    "\n",
    "    # Rouge 계산\n",
    "    result = rouge.compute(\n",
    "        predictions= pred_str,\n",
    "        references= label_str,\n",
    "        use_stemmer= True       # 점수 계산 시 단어의 어간을 기준으로 비교할 것인가?\n",
    "    )\n",
    "\n",
    "    # Rouge를 보기 편한 형태로 변경\n",
    "    result = { k: round(v * 100, 2) for k, v in result.items() }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6fa6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 파라미터 값을 지정 \n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir= \"./kobart\", \n",
    "    eval_strategy= 'epoch', \n",
    "    save_strategy= 'epoch', \n",
    "    learning_rate= 5e-5, \n",
    "    num_train_epochs= 1, \n",
    "    logging_steps=10, \n",
    "\n",
    "    # generate 설정을 변경 \n",
    "    predict_with_generate=True, \n",
    "    generation_max_length= 70, \n",
    "    # 요약 데이터를 생성할때 문장 후보의 탐색의 개수를 설정\n",
    "    generation_num_beams= 4, \n",
    "\n",
    "    load_best_model_at_end= True, \n",
    "    metric_for_best_model='rougeL', \n",
    "    greater_is_better=True, \n",
    "    report_to=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0df31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_14320\\780977535.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9/13 02:19 < 01:19, 0.05 it/s, Epoch 0.62/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer 생성 \n",
    "trainer = Seq2SeqTrainer(\n",
    "    model = model, \n",
    "    args=args, \n",
    "    train_dataset= tokenized_ds['train'], \n",
    "    eval_dataset=tokenized_ds['validation'], \n",
    "    tokenizer = tokenizer, \n",
    "    data_collator= data_collator, \n",
    "    compute_metrics= compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"과학기술정보통신부는 초거대 AI 연구 인프라 지원을 강화한다고 밝혔다. 스타트업 새당으로 GPU 리소스를 확대 제공할 계획이다.\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    test_text,\n",
    "    return_tensors = 'pt',\n",
    "    truncation = True,\n",
    "    max_length = max_input_len\n",
    ")\n",
    "inputs.pop('token_type_ids', None)\n",
    "\n",
    "# 이 부분을 바꾸는 게 중요\n",
    "gen_ids = model.generate(\n",
    "    **inputs.to(model.device),\n",
    "    max_new_tokens = 50,                    # 출력 토큰의 길이\n",
    "    min_new_tokens = 10,                    # 출력 토큰의 최소 길이\n",
    "    num_beams = 4,                          # n개의 후보 문장을 병렬적으로 추적하여 가장 가능성이 높은 문장을 선택\n",
    "    do_sample = False                       # 샘플링 사용 여부 (False: 빔 서치, True: 랜덤하게 선택)\n",
    "    length_penalty = 1.6,                   # 생성 길이에 대한 가중치 (반복적으로 요약문이 나오)\n",
    "    no_repeat_ngram_size = 5,               # 반복 방지\n",
    "    repetition_penalty = 1.5,               # 토큰 반복 패턴이 나타나는 경우 페널티 적용\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    pad_token_id = tokenizer.pad_token_id   # 안정성을 위한 옵션\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(gen_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a177f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
